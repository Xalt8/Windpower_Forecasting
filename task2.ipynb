{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-2: Wind Power Forecasting With Multiple Targets\n",
    "Author: Karan Singh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_parquet(r'../Case_Interview_-_Multitarget_Power_Forecasting/Case Interview - Multitarget Power Forecasting/data/labels.parquet', engine='pyarrow')\n",
    "weather = pd.read_parquet(r'../Case_Interview_-_Multitarget_Power_Forecasting/Case Interview - Multitarget Power Forecasting/data/weather_forecast.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the labels are in 15 minute resolution\n",
    "labels_index = pd.date_range(start=labels.index.min(), end=labels.index.max(), freq='15min')\n",
    "labels.index = labels_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features -> part of day & Month\n",
    "# Could temperature play a part? Is it cooler in the evenings/night?  \n",
    "# Can the months represent seasons?    \n",
    "\n",
    "conditions = [(0 <= labels.index.hour) & (labels.index.hour < 6), \n",
    "            (6 <= labels.index.hour) & (labels.index.hour < 12), \n",
    "            (12 <= labels.index.hour) & (labels.index.hour < 18), \n",
    "            (18 <= labels.index.hour) & (labels.index.hour < 24)]\n",
    "choices = [0, 1, 2, 3]\n",
    "labels['Day_part'] = np.select(condlist=conditions, choicelist=choices, default=np.nan)\n",
    "labels['Month'] = labels.index.month\n",
    "labels = labels[['Day_part', 'Month', 'power_1', 'power_2', 'power_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day_part</th>\n",
       "      <th>Month</th>\n",
       "      <th>power_1</th>\n",
       "      <th>power_2</th>\n",
       "      <th>power_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48637.0</td>\n",
       "      <td>51637.0</td>\n",
       "      <td>54637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52357.0</td>\n",
       "      <td>55357.0</td>\n",
       "      <td>58357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>54317.0</td>\n",
       "      <td>57317.0</td>\n",
       "      <td>60317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>54220.5</td>\n",
       "      <td>57220.5</td>\n",
       "      <td>60220.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51680.0</td>\n",
       "      <td>54680.0</td>\n",
       "      <td>57680.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Day_part  Month  power_1  power_2  power_3\n",
       "2019-01-01 00:00:00       0.0      1  48637.0  51637.0  54637.0\n",
       "2019-01-01 00:15:00       0.0      1  52357.0  55357.0  58357.0\n",
       "2019-01-01 00:30:00       0.0      1  54317.0  57317.0  60317.0\n",
       "2019-01-01 00:45:00       0.0      1  54220.5  57220.5  60220.5\n",
       "2019-01-01 01:00:00       0.0      1  51680.0  54680.0  57680.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation_Date</th>\n",
       "      <th>Forecast_Date</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>ws</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>2019-06-25 01:00:00</td>\n",
       "      <td>1.861707</td>\n",
       "      <td>0.195582</td>\n",
       "      <td>1.871952</td>\n",
       "      <td>264.002783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>2019-06-25 02:00:00</td>\n",
       "      <td>1.257695</td>\n",
       "      <td>0.570511</td>\n",
       "      <td>1.381043</td>\n",
       "      <td>245.600179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>2019-06-25 03:00:00</td>\n",
       "      <td>1.883554</td>\n",
       "      <td>0.701067</td>\n",
       "      <td>2.009794</td>\n",
       "      <td>249.584514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>2019-06-25 04:00:00</td>\n",
       "      <td>2.664914</td>\n",
       "      <td>0.169917</td>\n",
       "      <td>2.670325</td>\n",
       "      <td>266.351713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>2019-06-25 05:00:00</td>\n",
       "      <td>2.855113</td>\n",
       "      <td>-0.255226</td>\n",
       "      <td>2.866498</td>\n",
       "      <td>275.108242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Generation_Date       Forecast_Date         U         V        ws  \\\n",
       "1      2019-06-25 2019-06-25 01:00:00  1.861707  0.195582  1.871952   \n",
       "2      2019-06-25 2019-06-25 02:00:00  1.257695  0.570511  1.381043   \n",
       "3      2019-06-25 2019-06-25 03:00:00  1.883554  0.701067  2.009794   \n",
       "4      2019-06-25 2019-06-25 04:00:00  2.664914  0.169917  2.670325   \n",
       "5      2019-06-25 2019-06-25 05:00:00  2.855113 -0.255226  2.866498   \n",
       "\n",
       "    Direction  \n",
       "1  264.002783  \n",
       "2  245.600179  \n",
       "3  249.584514  \n",
       "4  266.351713  \n",
       "5  275.108242  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Generation_Date and make Forecast_Date the index \n",
    "weather = weather.drop('Generation_Date', axis=1).set_index('Forecast_Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>ws</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forecast_Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-25 01:00:00</th>\n",
       "      <td>1.861707</td>\n",
       "      <td>0.195582</td>\n",
       "      <td>1.871952</td>\n",
       "      <td>264.002783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-25 02:00:00</th>\n",
       "      <td>1.257695</td>\n",
       "      <td>0.570511</td>\n",
       "      <td>1.381043</td>\n",
       "      <td>245.600179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-25 03:00:00</th>\n",
       "      <td>1.883554</td>\n",
       "      <td>0.701067</td>\n",
       "      <td>2.009794</td>\n",
       "      <td>249.584514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-25 04:00:00</th>\n",
       "      <td>2.664914</td>\n",
       "      <td>0.169917</td>\n",
       "      <td>2.670325</td>\n",
       "      <td>266.351713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-25 05:00:00</th>\n",
       "      <td>2.855113</td>\n",
       "      <td>-0.255226</td>\n",
       "      <td>2.866498</td>\n",
       "      <td>275.108242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            U         V        ws   Direction\n",
       "Forecast_Date                                                \n",
       "2019-06-25 01:00:00  1.861707  0.195582  1.871952  264.002783\n",
       "2019-06-25 02:00:00  1.257695  0.570511  1.381043  245.600179\n",
       "2019-06-25 03:00:00  1.883554  0.701067  2.009794  249.584514\n",
       "2019-06-25 04:00:00  2.664914  0.169917  2.670325  266.351713\n",
       "2019-06-25 05:00:00  2.855113 -0.255226  2.866498  275.108242"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the labels and weather data\n",
    "data = pd.merge(left=labels, right=weather, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day_part</th>\n",
       "      <th>Month</th>\n",
       "      <th>power_1</th>\n",
       "      <th>power_2</th>\n",
       "      <th>power_3</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>ws</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48637.0</td>\n",
       "      <td>51637.0</td>\n",
       "      <td>54637.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52357.0</td>\n",
       "      <td>55357.0</td>\n",
       "      <td>58357.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>54317.0</td>\n",
       "      <td>57317.0</td>\n",
       "      <td>60317.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>54220.5</td>\n",
       "      <td>57220.5</td>\n",
       "      <td>60220.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51680.0</td>\n",
       "      <td>54680.0</td>\n",
       "      <td>57680.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Day_part  Month  power_1  power_2  power_3   U   V  ws  \\\n",
       "2019-01-01 00:00:00       0.0      1  48637.0  51637.0  54637.0 NaN NaN NaN   \n",
       "2019-01-01 00:15:00       0.0      1  52357.0  55357.0  58357.0 NaN NaN NaN   \n",
       "2019-01-01 00:30:00       0.0      1  54317.0  57317.0  60317.0 NaN NaN NaN   \n",
       "2019-01-01 00:45:00       0.0      1  54220.5  57220.5  60220.5 NaN NaN NaN   \n",
       "2019-01-01 01:00:00       0.0      1  51680.0  54680.0  57680.0 NaN NaN NaN   \n",
       "\n",
       "                     Direction  \n",
       "2019-01-01 00:00:00        NaN  \n",
       "2019-01-01 00:15:00        NaN  \n",
       "2019-01-01 00:30:00        NaN  \n",
       "2019-01-01 00:45:00        NaN  \n",
       "2019-01-01 01:00:00        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep values from the start date of weather \n",
    "data = data[np.where(data.index == weather.index.min())[0][0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the hourly values forward to quarter hour \n",
    "data['U'] = data['U'].fillna(method='ffill')\n",
    "data['V'] = data['V'].fillna(method='ffill')\n",
    "data['ws'] = data['ws'].fillna(method='ffill')\n",
    "data['Direction'] = data['Direction'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange so that power is the last column\n",
    "data = data[['Day_part', 'Month', 'U', 'V', 'ws', 'Direction', 'power_1','power_2','power_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day_part</th>\n",
       "      <th>Month</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>ws</th>\n",
       "      <th>Direction</th>\n",
       "      <th>power_1</th>\n",
       "      <th>power_2</th>\n",
       "      <th>power_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-25 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.861707</td>\n",
       "      <td>0.195582</td>\n",
       "      <td>1.871952</td>\n",
       "      <td>264.002783</td>\n",
       "      <td>4686.2</td>\n",
       "      <td>7686.2</td>\n",
       "      <td>10686.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-25 01:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.861707</td>\n",
       "      <td>0.195582</td>\n",
       "      <td>1.871952</td>\n",
       "      <td>264.002783</td>\n",
       "      <td>4047.9</td>\n",
       "      <td>7047.9</td>\n",
       "      <td>10047.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-25 01:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.861707</td>\n",
       "      <td>0.195582</td>\n",
       "      <td>1.871952</td>\n",
       "      <td>264.002783</td>\n",
       "      <td>3251.0</td>\n",
       "      <td>6251.0</td>\n",
       "      <td>9251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-25 01:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.861707</td>\n",
       "      <td>0.195582</td>\n",
       "      <td>1.871952</td>\n",
       "      <td>264.002783</td>\n",
       "      <td>2244.5</td>\n",
       "      <td>5244.5</td>\n",
       "      <td>8244.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-25 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.257695</td>\n",
       "      <td>0.570511</td>\n",
       "      <td>1.381043</td>\n",
       "      <td>245.600179</td>\n",
       "      <td>2224.6</td>\n",
       "      <td>5224.6</td>\n",
       "      <td>8224.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Day_part  Month         U         V        ws  \\\n",
       "2019-06-25 01:00:00       0.0      6  1.861707  0.195582  1.871952   \n",
       "2019-06-25 01:15:00       0.0      6  1.861707  0.195582  1.871952   \n",
       "2019-06-25 01:30:00       0.0      6  1.861707  0.195582  1.871952   \n",
       "2019-06-25 01:45:00       0.0      6  1.861707  0.195582  1.871952   \n",
       "2019-06-25 02:00:00       0.0      6  1.257695  0.570511  1.381043   \n",
       "\n",
       "                      Direction  power_1  power_2  power_3  \n",
       "2019-06-25 01:00:00  264.002783   4686.2   7686.2  10686.2  \n",
       "2019-06-25 01:15:00  264.002783   4047.9   7047.9  10047.9  \n",
       "2019-06-25 01:30:00  264.002783   3251.0   6251.0   9251.0  \n",
       "2019-06-25 01:45:00  264.002783   2244.5   5244.5   8244.5  \n",
       "2019-06-25 02:00:00  245.600179   2224.6   5224.6   8224.6  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Random Forest Regression to impute missing power values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_powers_mask = (data['power_1'].isnull()) & (data['power_2'].isnull()) & (data['power_3'].isnull())   \n",
    "data.loc[missing_powers_mask].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "powers_present_mask = (data['power_1'].notnull()) & (data['power_2'].notnull()) & (data['power_3'].notnull())\n",
    "data[powers_present_mask]\n",
    "rf_inputs = data[powers_present_mask].drop(['power_1', 'power_2', 'power_3'], axis=1)\n",
    "rf_labels = data[powers_present_mask][['power_1','power_2', 'power_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(rf_inputs, rf_labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9702429823830423"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MultiOutputRegressor(RandomForestRegressor(n_estimators=50))\n",
    "regr.fit(X_train, y_train)\n",
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values that are missing\n",
    "pred_data = data.loc[missing_powers_mask].drop(['power_1', 'power_2', 'power_3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regr.predict(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, pred in zip(data[missing_powers_mask].index, predictions):\n",
    "    data.loc[ind,'power_1'] = pred[0]\n",
    "    data.loc[ind,'power_2'] = pred[1]\n",
    "    data.loc[ind,'power_3'] = pred[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Day_part     0\n",
       "Month        0\n",
       "U            0\n",
       "V            0\n",
       "ws           0\n",
       "Direction    0\n",
       "power_1      0\n",
       "power_2      0\n",
       "power_3      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date to split the training and testing\n",
    "index_1Aug2020 = np.where(data.index == '2020-08-01 00:00:00')[0][0] \n",
    "\n",
    "training_data = data[:index_1Aug2020] \n",
    "testing_data = data[index_1Aug2020:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that training data starts at 00:15:00 and ends at 00:00:00\n",
    "training_data = training_data.loc['2019-06-26 00:15:00':'2020-07-30 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the labels for X\n",
    "training_X = training_data.iloc[:,:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 96, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the training data into chunks of 96\n",
    "X = np.array(np.split(training_X, training_X.shape[0]//96))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day_part</th>\n",
       "      <th>Month</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>ws</th>\n",
       "      <th>Direction</th>\n",
       "      <th>power_1</th>\n",
       "      <th>power_2</th>\n",
       "      <th>power_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-26 00:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.202267</td>\n",
       "      <td>1.753324</td>\n",
       "      <td>2.814982</td>\n",
       "      <td>231.475115</td>\n",
       "      <td>7021.0</td>\n",
       "      <td>10021.0</td>\n",
       "      <td>13021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-26 00:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.202267</td>\n",
       "      <td>1.753324</td>\n",
       "      <td>2.814982</td>\n",
       "      <td>231.475115</td>\n",
       "      <td>6050.6</td>\n",
       "      <td>9050.6</td>\n",
       "      <td>12050.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-26 00:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.202267</td>\n",
       "      <td>1.753324</td>\n",
       "      <td>2.814982</td>\n",
       "      <td>231.475115</td>\n",
       "      <td>7160.7</td>\n",
       "      <td>10160.7</td>\n",
       "      <td>13160.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-26 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.593115</td>\n",
       "      <td>0.233521</td>\n",
       "      <td>1.610139</td>\n",
       "      <td>261.660883</td>\n",
       "      <td>6447.0</td>\n",
       "      <td>9447.0</td>\n",
       "      <td>12447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-26 01:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.593115</td>\n",
       "      <td>0.233521</td>\n",
       "      <td>1.610139</td>\n",
       "      <td>261.660883</td>\n",
       "      <td>5422.2</td>\n",
       "      <td>8422.2</td>\n",
       "      <td>11422.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Day_part  Month         U         V        ws  \\\n",
       "2019-06-26 00:15:00       0.0      6  2.202267  1.753324  2.814982   \n",
       "2019-06-26 00:30:00       0.0      6  2.202267  1.753324  2.814982   \n",
       "2019-06-26 00:45:00       0.0      6  2.202267  1.753324  2.814982   \n",
       "2019-06-26 01:00:00       0.0      6  1.593115  0.233521  1.610139   \n",
       "2019-06-26 01:15:00       0.0      6  1.593115  0.233521  1.610139   \n",
       "\n",
       "                      Direction  power_1  power_2  power_3  \n",
       "2019-06-26 00:15:00  231.475115   7021.0  10021.0  13021.0  \n",
       "2019-06-26 00:30:00  231.475115   6050.6   9050.6  12050.6  \n",
       "2019-06-26 00:45:00  231.475115   7160.7  10160.7  13160.7  \n",
       "2019-06-26 01:00:00  261.660883   6447.0   9447.0  12447.0  \n",
       "2019-06-26 01:15:00  261.660883   5422.2   8422.2  11422.2  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 96)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign power_1 to y_1 and split it into 96 daily values \n",
    "y_1 = training_data['power_1'].values\n",
    "y_1 = np.array(np.split(y_1, y_1.shape[0]/96))\n",
    "y_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 96)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign power_2 to y_2 and split it into 96 daily values \n",
    "y_2 = training_data['power_2'].values\n",
    "y_2 = np.array(np.split(y_2, y_2.shape[0]/96))\n",
    "y_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 96)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign power_3 to y_3 and split it into 96 daily values \n",
    "y_3 = training_data['power_3'].values\n",
    "y_3 = np.array(np.split(y_3, y_3.shape[0]/96))\n",
    "y_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 576)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten X\n",
    "n_input = X.shape[1] * X.shape[2]\n",
    "X = X.reshape((X.shape[0], n_input))\n",
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the output dimension\n",
    "n_output = y_1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split 20%\n",
    "X_train = X[:320]\n",
    "X_test = X[320:]\n",
    "\n",
    "y_train_1 = y_1[:320]\n",
    "y_test_1 = y_1[320:]\n",
    "\n",
    "y_train_2 = y_2[:320]\n",
    "y_test_2 = y_2[320:]\n",
    "\n",
    "y_train_3 = y_3[:320]\n",
    "y_test_3 = y_3[320:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc_X = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_mean_abs_error(y_true, y_pred):\n",
    "    ''' Custom loss function '''\n",
    "    return 100*((np.sum(np.abs(y_true - y_pred))/y_true.size)/106400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from keras.layers import Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiLMLayer(layers.Layer):\n",
    "    def __init__(self, gamma, beta, switch):\n",
    "      super(FiLMLayer, self).__init__()\n",
    "\n",
    "      self.gamma = gamma\n",
    "      self.beta = beta\n",
    "      self.switch = switch\n",
    "\n",
    "    def call(self, input):\n",
    "      if self.switch == 1:\n",
    "        return tf.math.multiply(self.gamma[0], input) + self.beta[0]\n",
    "      elif self.switch == 2:\n",
    "        return tf.math.multiply(self.gamma[1], input) + self.beta[1]\n",
    "      else: \n",
    "        return tf.math.multiply(self.gamma[2], input) + self.beta[2]\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBlock(Sequential):\n",
    "    def __init__(self):\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.switch = tf.Variable(1)\n",
    "        self.gamma = tf.Variable(initial_value=tf.random.uniform(shape=(3,200), minval=0, maxval=1, dtype=tf.dtypes.float32), trainable=True) \n",
    "        self.beta = tf.Variable(initial_value=tf.random.uniform(shape=(3,200), minval=0, maxval=1, dtype=tf.dtypes.float32), trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.add(Dense(200, activation='relu', input_dim=n_input, name=\"Dense1\"))\n",
    "mlp.add(FiLMLayer(mlp.gamma, mlp.beta, mlp.switch))\n",
    "mlp.add(Dense(200, activation='relu', input_dim=n_input, name=\"Dense2\"))\n",
    "mlp.add(Dense(n_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = mlp(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mlp_block\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense1 (Dense)              (None, 200)               115400    \n",
      "                                                                 \n",
      " fi_lm_layer (FiLMLayer)     (None, 200)               1201      \n",
      "                                                                 \n",
      " Dense2 (Dense)              (None, 200)               40200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 96)                19296     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 176,097\n",
      "Trainable params: 176,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "# mse = tf.keras.losses.MeanSquaredError()\n",
    "loss_metric = tf.keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_nmae(y_true, y_pred):\n",
    "    abs_diff = tf.abs(y_true - y_pred)\n",
    "    return 100*(tf.reduce_sum(abs_diff)/y_true.shape[0])/106400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress warnings\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "Loss:7585.283203125\n",
      "Start of epoch 1\n",
      "Loss:7585.232421875\n",
      "Start of epoch 2\n",
      "Loss:7585.177734375\n",
      "Start of epoch 3\n",
      "Loss:7585.115234375\n",
      "Start of epoch 4\n",
      "Loss:7585.0380859375\n",
      "Start of epoch 5\n",
      "Loss:7584.9453125\n",
      "Start of epoch 6\n",
      "Loss:7584.83251953125\n",
      "Start of epoch 7\n",
      "Loss:7584.697265625\n",
      "Start of epoch 8\n",
      "Loss:7584.537109375\n",
      "Start of epoch 9\n",
      "Loss:7584.3466796875\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "# Iterate over epochs.\n",
    "for epoch in range(epochs):\n",
    "    print(\"Start of epoch %d\" % (epoch,))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        mlp.switch.assign(1)\n",
    "        y_pred1 = mlp(X_train)\n",
    "        loss = tf_nmae(y_true=y_train_1, y_pred=y_pred1)\n",
    "        \n",
    "        mlp.switch.assign(2)\n",
    "        y_pred2 = mlp(X_train)\n",
    "        loss += tf_nmae(y_true=y_train_2, y_pred=y_pred2)\n",
    "        \n",
    "        mlp.switch.assign(3)\n",
    "        y_pred3 = mlp(X_train)\n",
    "        loss += tf_nmae(y_true=y_train_3, y_pred=y_pred3)\n",
    "        \n",
    "    print(f\"Loss:{loss}\")\n",
    "    tf.cast(loss, dtype=tf.float32, name=None)\n",
    "    grads = tape.gradient(loss, mlp.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, mlp.trainable_weights))\n",
    "\n",
    "    loss_metric(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction model with different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FiLMLayer2(Layer):\n",
    "#     def __init__(self, **kwargs):\n",
    "#       super(FiLMLayer2, self).__init__(**kwargs)\n",
    "\n",
    "#       self.switch = tf.Variable(1)\n",
    "    \n",
    "#     def build(self, input_shape):\n",
    "#         self.gamma = self.add_weight(name=\"gamma_weight\", shape=((3, input_shape)), initializer='random_normal', trainable=True)\n",
    "#         self.beta = self.add_weight(name=\"beta_weight\", shape=((3, input_shape)), initializer='random_normal', trainable=True)\n",
    "#         super(FiLMLayer2, self).build(input_shape)\n",
    "\n",
    "#     def call(self, input):\n",
    "#       if self.switch == 1:\n",
    "#         return tf.math.multiply(self.gamma[0], input) + self.beta[0]\n",
    "#       elif self.switch == 2:\n",
    "#         return tf.math.multiply(self.gamma[1], input) + self.beta[1]\n",
    "#       else: \n",
    "#         return tf.math.multiply(self.gamma[2], input) + self.beta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FL(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(FL,self).__init__(**kwargs)\n",
    "\n",
    "        self.switch = tf.Variable(1)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(name=\"gamma_weight\", shape=(3, 200), initializer='random_normal', trainable=True)\n",
    "        self.beta = self.add_weight(name=\"beta_weight\", shape=(3, 200), initializer='random_normal', trainable=True)\n",
    "        super(FL, self).build(input_shape)\n",
    "    \n",
    "    def call(self, input):\n",
    "        if self.switch == 1:\n",
    "            return tf.math.multiply(self.gamma[0], input) + self.beta[0]\n",
    "        elif self.switch == 2:\n",
    "            return tf.math.multiply(self.gamma[1], input) + self.beta[1]\n",
    "        else:\n",
    "            return tf.math.multiply(self.gamma[2], input) + self.beta[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(200, activation='relu', input_dim=n_input, name='Dense1'))\n",
    "# model.add(FL())\n",
    "# model.add(Dense(200, activation='relu'))\n",
    "# model.add(Dense(n_output))\n",
    "# model.compile(loss='mse', optimizer='adam')\n",
    "# model.fit(X_train, y_train, epochs=20, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputLayer = keras.Input(shape=(n_input))\n",
    "dense_layer2= Dense(200, activation='relu', name=\"Dense1\")(inputLayer)\n",
    "film_layer = FL()(dense_layer2)\n",
    "dense_layer2 = Dense(200, activation='relu', name=\"Dense2\")(film_layer)\n",
    "outputLayer = Dense(n_output)(dense_layer2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputLayer,outputLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2].switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 576)]             0         \n",
      "                                                                 \n",
      " Dense1 (Dense)              (None, 200)               115400    \n",
      "                                                                 \n",
      " fl (FL)                     (None, 200)               1201      \n",
      "                                                                 \n",
      " Dense2 (Dense)              (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                19296     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 176,097\n",
      "Trainable params: 176,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "Loss:7585.28271484375\n",
      "Start of epoch 1\n",
      "Loss:7585.2822265625\n",
      "Start of epoch 2\n",
      "Loss:7585.28125\n",
      "Start of epoch 3\n",
      "Loss:7585.2783203125\n",
      "Start of epoch 4\n",
      "Loss:7585.27685546875\n",
      "Start of epoch 5\n",
      "Loss:7585.2734375\n",
      "Start of epoch 6\n",
      "Loss:7585.26953125\n",
      "Start of epoch 7\n",
      "Loss:7585.2646484375\n",
      "Start of epoch 8\n",
      "Loss:7585.2578125\n",
      "Start of epoch 9\n",
      "Loss:7585.25\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "# Iterate over epochs.\n",
    "for epoch in range(epochs):\n",
    "    print(\"Start of epoch %d\" % (epoch,))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        model.layers[2].switch.assign(1)\n",
    "        y_pred1 = model(X_train)\n",
    "        loss = tf_nmae(y_true=y_train_1, y_pred=y_pred1)\n",
    "        \n",
    "        model.layers[2].switch.assign(2)\n",
    "        y_pred2 = model(X_train)\n",
    "        loss += tf_nmae(y_true=y_train_2, y_pred=y_pred2)\n",
    "        \n",
    "        model.layers[2].switch.assign(3)\n",
    "        y_pred3 = model(X_train)\n",
    "        loss += tf_nmae(y_true=y_train_3, y_pred=y_pred3)\n",
    "        \n",
    "    print(f\"Loss:{loss}\")\n",
    "    # tf.cast(loss, dtype=tf.float32, name=None)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    loss_metric(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].switch.assign(1)\n",
    "testPredict1 = model(X_test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2028.5663"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_nmae(y_true=y_test_1, y_pred=testPredict1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        if len(data) == 4:\n",
    "            x,y1,y2,y3 = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            self.layers[2].switch.assign(1)\n",
    "            y_pred1 = self(X_train, training=True)\n",
    "            loss = tf_nmae(y_true=y_train_1, y_pred=y_pred1)\n",
    "            \n",
    "            self.layers[2].switch.assign(2)\n",
    "            y_pred2 = model(X_train)\n",
    "            loss += tf_nmae(y_true=y_train_2, y_pred=y_pred2)\n",
    "            \n",
    "            self.layers[2].switch.assign(3)\n",
    "            y_pred3 = model(X_train)\n",
    "            loss += tf_nmae(y_true=y_train_3, y_pred=y_pred3)\n",
    "        \n",
    "        print(f\"Loss:{loss}\")\n",
    "        # tf.cast(loss, dtype=tf.float32, name=None)\n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        loss_metric(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8736, 9)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_split = np.array(np.split(test_data , test_data.shape[0]//96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 96, 9)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 864)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten test_data_split\n",
    "n_input2 = test_data_split.shape[1] * test_data_split.shape[2]\n",
    "test_data_flat = test_data_split.reshape((test_data_split.shape[0], n_input2))\n",
    "test_data_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler_test = MinMaxScaler(feature_range=(0, 1))\n",
    "test_data_scaled = sc_X.fit_transform(test_data_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 864)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\env\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 576), found shape=(None, 864)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\task2.ipynb Cell 74\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/singh/OneDrive/Documents/Job/Jungle/task/code/task2.ipynb#ch0000075?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mpredict(test_data_scaled)\n",
      "File \u001b[1;32mc:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileesvclk9_.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\singh\\OneDrive\\Documents\\Job\\Jungle\\task\\code\\env\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 576), found shape=(None, 864)\n"
     ]
    }
   ],
   "source": [
    "model.predict(test_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9caa281ebeb769b9d8f87ec84c8c596a157648216885e09be5c1427422d5d8cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
